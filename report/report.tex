%\documentclass{report}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}

\usepackage[left=30mm,right=15mm,
top=20mm,bottom=20mm,bindingoffset=0cm]{geometry}
%\usepackage{titling}

\usepackage{indentfirst}  % подавить механизм, убирающий красную строку в пермом абзаце после section

%\usepackage{mdwlist}
\usepackage{enumitem}

\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\newenvironment{itemize*}%
	{\begin{itemize}[topsep=0pt, partopsep=0pt, itemsep=0pt,parsep=0pt]}	
	{\end{itemize}}

\begin{document}
	
\title{Задача поиска кратчайших путей между всеми вершинами взвешенного ориентированного графа алгоритмом Флойда---Уоршелла}
\author{Петренко Владимир\\Голов Руслан}


\begin{titlepage}
	\maketitle
	\begin{abstract}
		Поставлена задача поиска кратчайших путей между всеми вершинами взвешенного ориентированного графа. Рассмотрен алгоритм Флойда---Уоршелла, решающий данную задачу. Предложена адаптация алгоритма Флойда---Уоршелла для параллельных вычислений. Проведен анализ вычислительных сложностей последовательного и параллельного вариантов исполнения алгоритма. Приведены результаты выполнения эксперимента и их анализ.
	\end{abstract}
\end{titlepage}



\section{Постановка задачи}

	Поставлена задача поиска кратчайших путей между всеми вершинами взвешенного ориентированного графа.
	
	Пусть задан взвешенный ориентированный граф \(G=(V,R)\), где \(V\)---множество вершин графа, а \(R\)---множество ребер. Пусть \(|V|=n\)---количество вершин графа.
	
	Требуется найти максимально возможно короткий путь между каждой парой вершин графа \(G\).

\section{Алгоритм Флойда---Уоршелла}

	Пусть вершины графа \(G=(V, E),\; |V| = n\) пронумерованы от 1 до \(n\) и введено обозначение \(d_{i j}^{k}\) для длины кратчайшего пути от \(i\) до \(j\), который кроме самих вершин \(i,\; j\) проходит только через вершины \(\overline{1..k}\). Очевидно, что \(d_{i j}^{0}\) — длина (вес) ребра \((i,\;j)\), если таковое существует (в противном случае его длина может быть обозначена как \(\infty\)).
	
	Существует два варианта значения \(d_{i j}^{k},\;k \in (1,\;\ldots,\;n)\):
	\begin{itemize*}
		\item Кратчайший путь между \(i,\;j\) не проходит через вершину \(k\), тогда \(d_{i j}^{k}=d_{i j}^{k-1}\)
		\item Существует более короткий путь между \(i,\;j\), проходящий через \(k\), тогда он сначала идёт от \(i\) до \(k\), а потом от \(k\) до \(j\). В этом случае, очевидно, \(d_{i j}^{k}=d_{i k}^{k-1} + d_{k j}^{k-1}\)
	\end{itemize*}
	
	Таким образом, для нахождения значения функции достаточно выбрать минимум из двух обозначенных значений.
	
	Тогда рекуррентная формула для \(d_{i j}^k\) имеет вид:
	
	\(
		\left\{
			\begin{array}{ll}
				d_{i j}^0 - \mbox{длина ребра } (i,\;j); \\
				d_{i j}^{k} = \min (d_{i j}^{k-1},\; d_{i k}^{k-1} + d_{k j}^{k-1}).
			\end{array}
		\right.
	\)
	
	Алгоритм Флойда-Уоршелла последовательно вычисляет все значения \(d_{i j}^{k},\) \(\forall i,\; j\) для \(k\) от 1 до \(n\). Полученные значения \(d_{i j}^{n}\) являются длинами кратчайших путей между вершинами \(i,\; j.\)
	
	\subsection{Алгоритм}
	
		Пусть имеем матрицу смежности $A$:
		
		\begin{displaymath}
			A =
			\left(
				\begin{array}{cccc}
					a_{11} & a_{12} & \dots  & a_{1n} \\
					a_{21} & a_{22} & \dots  & a_{2n} \\
					\vdots & \vdots & \ddots & \vdots \\
					a_{n1} & a_{n2} & \dots  & a_{nn} \\
				\end{array} 
			\right)
		\end{displaymath}
		
		Запишем новую матрицу $W^0 = A$:
		
		\begin{displaymath}
			W^0 =
			\left(
				\begin{array}{cccc}
					d_{11}^{0} & d_{12}^{0} & \dots  & d_{1n}^{0} \\
					d_{21}^{0} & d_{22}^{0} & \dots  & d_{2n}^{0} \\
					\vdots     & \vdots     & \ddots & \vdots     \\
					d_{n1}^{0} & d_{n2}^{0} & \dots  & d_{nn}^{0} \\
				\end{array} 
			\right), \mbox{где}\; d_{ij}^{n} = a_{ij},\;i,j=\overline{1..n}
		\end{displaymath}
		
		Далее применим к ней следующее преобразование:
		
		\begin{verbatim}
		for k = 1 to n
		  for i = 1 to n
		    for j = 1 to n
		      W[i][j] = min(W[i][j], W[i][k] + W[k][j])
		\end{verbatim}
		
		Полученная после преобразования матрица $W^n$ будет соответствовать длинам кратчайших путей, т.е.:
		
		\begin{displaymath}
			W^n =
			\left(
				\begin{array}{cccc}
					d_{11}^{n} & d_{12}^{n} & \dots  & d_{1n}^{n} \\
					d_{21}^{n} & d_{22}^{n} & \dots  & d_{2n}^{n} \\
					\vdots     & \vdots     & \ddots & \vdots     \\
					d_{n1}^{n} & d_{n2}^{n} & \dots  & d_{nn}^{n} \\
				\end{array} 
			\right)
		\end{displaymath}
		

\section{Адаптация алгоритма Флойда---Уоршелла для параллельных вычислений}

	Т.к. каждый шаг $k$ преобразования матрицы $W$ зависит от предыдущего состояния $W$, то выполнение шагов придется выполнять последовательно.
	
	Пусть после выполнения шага $k$ имеем состояние матрицы $W^k$, т.е.:
	
	\begin{displaymath}
		W^k =
		\left(
			\begin{array}{cccc}
				d_{11}^{k} & d_{12}^{k} & \dots  & d_{1n}^{k} \\
				d_{21}^{k} & d_{22}^{k} & \dots  & d_{2n}^{k} \\
				\vdots     & \vdots     & \ddots & \vdots     \\
				d_{n1}^{k} & d_{n2}^{k} & \dots  & d_{nn}^{k} \\
			\end{array} 
		\right)
	\end{displaymath}
	
	Следуя алгоритму на шаге $k$ необходимо для каждых $i,j=\overline{1..n}$ выполнить операцию:
	
	\begin{equation} \label{updateElement}
		d_{i j}^{k} = \min (d_{i j}^{k-1},\; d_{i k}^{k-1} + d_{k j}^{k-1})
	\end{equation}
	
	Т.к. выполнение данной операции никак не влияет на используемые в ней аргументы $d_{i j}^{k-1}$, $d_{i k}^{k-1}$ и $d_{k j}^{k-1}$, то теоретически все такие операции на шаге $k$ можно выполнять параллельно.
	
	В рассуждениях выше подразумевается, что каждое $W^k,\; k=\overline{1..n}$ хранится в памяти отдельно. Однако для больших $n$ данный способ хранения стоит оптимизировать. 
	
	На каждом шаге $k$ необходимо помнить значение матрицы $W^{k-1}$ и выделить память под матрицу $W^{k}$, поэтому все остальные предыдущие состояния матрицы $W$ можно не хранить.

	Однако можно пойти дальше, и на каждом шаге $k$ результат операции \ref{updateElement} перезаписывать в $i,j$-ячейку той же матрицы $W^{k-1}$, т.к. в независимости от того, для каких $i,j$ операция \ref{updateElement} уже выполнилась, а для каких еще нет, значения аргументов это операции (т.е. элементов $d_{i j}^{k-1}$, $d_{i k}^{k-1}$ и $d_{k j}^{k-1}$) не изменяются.
	
	Доказательство: 
	\begin{enumerate}
		\item Пусть $i=k\; \Rightarrow\; d_{k j}^{k} = \min (d_{k j}^{k-1},\; d_{k k}^{k-1} + d_{k j}^{k-1})$. Очевидно, что $d_{k k}^{k-1}=0 \; \Rightarrow \; d_{k j}^{k} = \min (d_{k j}^{k-1},\; d_{k j}^{k-1}) \; \Rightarrow \; d_{k j}^{k} = d_{k j}^{k-1}, \; j=\overline{1..n} \;  \Rightarrow $ аргумент $d_{k j}^{k-1}$ не может измениться даже, если операция \ref{updateElement} была над ним произведена.
		\item Пусть $j=k$. По аналогии $\Rightarrow \; d_{i k}^{k} = d_{i k}^{k-1}, \; i=\overline{1..n} \;  \Rightarrow $ аргумент $d_{i k}^{k-1}$ не может измениться даже, если операция \ref{updateElement} была над ним произведена.
		\item Аргумент $d_{i j}^{k-1}$ может быть изменен только текущей операцией, поэтому до выполнения операции его значения тоже можно считать неизменным.
	\end{enumerate}
	
	Получается, что для выполнения преобразования достаточно хранить в памяти только лишь один экземпляр матрицы $W$. 
	
	
\section{Вычислительная сложность}
	
	\subsection{Последовательный вариант} \label{consistentWay}
	
	Асимптотическая вычислительная сложность выполнения операции \ref{updateElement} равна $O(1)$. Так как нам для каждого шага $k$ необходимо применить данную операцию к каждой ячейке матрицы $W$, а размер матрицы $W$ равен $n^2$, то сложность выполнения $k$-го шага будет равна $O(n^2)$. Таких шагов выполняется $k$, следовательно, сложность выполнения алгоритма будет равна:
	
	\begin{equation} \label{consistentEquationDifficulty}
		T(n) = O(n^2)  \cdot  O(n) = O(n^3)
	\end{equation}
	
	Как было описано ранее, для выполнения данного алгоритма в параллельном варианте достаточно хранить в памяти один экземпляр матрицы $W$, а значит, и для
	последовательного варианта этого будет достаточно. Хранение матрицы $W$ занимает в памяти $O(n^2)$. Помимо самой матрицы для выполнения алгоритма понадобится ограниченный набор переменных, что занимает $O(1)$. Итого выполнение последовательного варианта алгоритма имеет сложность по памяти:
	
	\begin{equation} \label{consistentMemoryDifficulty}
		P_c(n) = O(n^2) + O(1) = O(n^2)
	\end{equation}
	
	
	\subsection{Параллельный вариант}
	
		\subsubsection{Идеальный теоретический параллельный вариант}
		
			Предположим, что нет ограничений на количество потоков выполнения вычислений, нет никаких расходов на синхронизацию и т.д. Пусть $t$ --- количество потоков выполнения вычислений. Чтобы добиться максимальной скорости, необходимо распределить нагрузку на каждый поток равномерно. Следовательно, нужно за каждым потоком закрепить не более $\hat n = \ceil*{\dfrac{n^2}{t}}$ ячеек (элементов матрицы $W$). Стоит учитывать, что каждая ячейка может обрабатываться в один момент времени лишь одним потоком.
			
			Если $t \geq n^2$, получаем вырожденный случай: $\hat n = 1$, т.к. $n^n$ потоков будут обрабатывать каждый по одной ячейке, а остальные $t-n^2$ будут простаивать. Этот случай настолько далек от реальности, что не будем его больше рассматривать. Поэтому далее будем полагать, что $t \leq n^2$.
			
			Очевидно, что, чем больше ячеек обрабатывает поток, тем дольше у него уходит на это времени. Поэтому при указанном выше распределении нагрузки сложность вычисления будем расчитывать по потоку, обрабатывающему $\hat n$ ячеек.
			
			На обработку одной ячейки, т.е. на выполнения одной операции \ref{updateElement} уходит $O(1)$ времени. На шаге $k$ поток, обрабатывающий $\hat n$ ячеек, тратит $O(1) \cdot O(\hat n) = O(\hat n)$ времени. Так как при выполнении шага $k$ все потоки работают одновременно, то и закончат все они не позже, чем через $O(\hat n)$. Всего $n$ шагов, которые необходимо выполнять последовательно. При подсчете асимптотик сложности можно считать, что $\hat n = n / t$. Поэтому результирующая сложность для параллельного варианта алгоритма будет следующая:
			
			\begin{equation} \label{parallelPerfectEquationDifficulty}
				T'_p(n,t) = O(n)  \cdot  O(\hat n) =
				O(n  \cdot  \hat n) =
				O\left( n \cdot \dfrac{n^2}{t} \right) =
				O\left( \dfrac{n^3}{t} \right)
			\end{equation}
			
			Заметим, что, если $t=1$, то получим тот же результат, что и в Разделе \ref{consistentWay}:
			
			$$
				T'_p(n,1) = O\left( \dfrac{n^3}{1} \right)
				= O(n^3) = T_c(n)
			$$
			
			Касательно памяти имеем, помимо расходов, связанных с хранением одного экземпляра матрицы $W$ и некоторого фиксированного набора переменных, связанных с вычислением, необходимость хранить данные, обеспечивающие организацию совместной работы всех потоков. Как правило, это какой-то глобальный фиксированный набор переменных, занимающий $O(1)$ памяти, и фиксированный набор переменных для каждого потока, суммарно дающий $O(t) \cdot O(1) = O(t)$ сложности по памяти.
			
			Результирующая сложность по памяти для идеального параллельного варианта:
			
			\begin{equation} \label{parallelPerfectMemoryDifficulty}
				P'_p(n,t) = P_c(n) + O(1) + O(t) = O(n^2) + O(t) = O(n^2+t)
			\end{equation}
		
			
		\subsection{Параллельный вариант на практике}
		
			На практике все гораздо сложнее. Оценка сложности по времени, приведенная в Формуле \ref{parallelPerfectEquationDifficulty}, будет работать лишь при $t \leq T_{phy}$, где $t_{rp}$ - количество реальных физических потоков, причем имеющих равные вычислительные мощности.		
			
			Также существует проблема с разделенной памятью, т.е. обращаться к общей памяти в один момент времени может лишь один поток, что приводит к блокировкам всех других потоков, которые в этот же момент будут пытаться обратиться к данным из памяти.
			
			Приведем приближенную к реальности формулу оценки сложности:
			
			\begin{equation}\label{parallelRealEquationDifficulty}
				T_p(n,t,T_{phy}) = 
				\left\{
					\begin{array}{ll}
						T'_p(n,t) = O\left( \dfrac{n^3}{t} \right) 
						& \mbox{, если } t \leq T_{phy} 
						\\ 
						T'_p(n,T_{phy}) = O\left( \dfrac{n^3}{T_{phy}} \right)  
						& \mbox{, если } t > T_{phy} \\
					\end{array}
				\right.
			\end{equation}
			
			Касательно памяти, формула \ref{parallelPerfectMemoryDifficulty} применима и для этого случая:
			
			$$
				P_p(n,t) = P'_p(n,t) = P(n^2)
			$$
			
\section{Экспериментальная часть}

	Была написана программа на языке Java, позволяющая произвести преобразование матрицы $W$ параллельным алгоритмом Флойда-Уоршелла. 
	
	На вход программе подаются переменные $n$ --- размер матрицы $W$ и $t$ --- количество потоков, в которых следует производить вычисления.
	
	Вы выходе программа выдает преобразованную матрицу $W^n$.
	
	Для различных наборов пар $(n,t)$ были выполнены замеры времени, которое требуется программе на вычисление. Время работы этапов подготовки (создание потоков, выделение памяти, генерация исходной матрицы $W$) и завершения (вывод данных, завершение потоков выполнения, очистка памяти) находятся вне измеряемого промежутка времени.
	
	Для чистоты результатов измерений для каждой пары $(n,t)$ было выполнено $r$ повторов работы программы, причем на различных случайно сгенерированных исходных $W$. За результат измерения времени работы программы на данных $(n,t)$ принято $e_{n,t}$, равное среднему арифметическому от результатов измерений на всех $r$ повторах.
	
	Эксперимент проводился на ЭВМ с процессором Intel Core i7. Время измерялось в миллисекундах.
	
	В результате получены следующие результаты:
	
	\begin{table}
	\caption{Результаты эксперимента}
	\begin{center}
	\begin{tabular}{ | l | rrrrrr | }
		\hline
		$e_{n,t}$ & $t=1$   & $t=2$  & $t=4$  & $t=8$  & $t=16$ & $t=32$ \\ 
		\hline        
		$n=100$   & 14      & 8      & 8      & 10     & 13     & 21     \\
		$n=300$   & 308     & 162    & 91     & 69     & 71     & 87     \\
		$n=500$   & 1352    & 715    & 397    & 300    & 276    & 290    \\
		$n=1000$  & 10648   & 5421   & 2914   & 2122   & 2038   & 2003   \\
		\hline
		\end{tabular}
	\end{center}
	\end{table}
	
	При $n=100$ можно видеть прирост в скорости только при переходе от однопоточного варианта к двупоточному. Дальнейшее падение производительности при повышении числа потоков можно объяснить высокой долей накладных расходов, связанных с организацией работы многопоточности и ее особенностями. Подобный эффект можно наблюдать на парах $n,t$: $(300,16)$, $(300,32)$ и $(500,32)$.
	
	Начиная с $n=300$ и более прирост в производительности наблюдается практически в точности в соответствии с Формулами \ref{parallelPerfectEquationDifficulty} \ref{parallelRealEquationDifficulty} (вычислительные сложности для идеального и практического вариантов), что подтверждает теоретические выкладки.
	
	При увеличении количества потоков с $4$ до $8$, производительность увеличивается не в $2$ раза, как ожидается, а примерно в $1.2-1.3$ раза. Это объясняется тем, что у процессоров семейства Intel Core i7 физически существует 4 ядра, но с помощью технологии Hyper-Threading на каждом физическом ядре работают 2 виртуальных потока, т.е. всего $8$ однако у этих потоков не одинаковая производительность, поэтому в эксперименте мы и получили незначительное ускорение.
	
	Упомянутые выше $8$ виртуальных потока можно считать физически параллельными потоками, поэтому при дальнейшем повышении числа потоков $t$ в соответствии с формулой \ref{parallelRealEquationDifficulty} производительность не должна расти. Если в результатах эксперимента для $n=1000$ не учитывать $1\%-5\%$ повышения производительности при увеличении $t$ до $16$ и $32$, то результат эксперимента соответствует теории.
	
	Упомянутое выше небольшое ускорение можно объяснить тем, что на ЭВМ, помимо экспериментальной программы, выполняются процессы других программ, потоки которых выполняются параллельно на этом же процессоре, т.е. стоят в очереди на распределение процессорного времени и отнимают его незначительную часть у экспериментальной программы.
	
	При увеличении $t$ до $16$ и $32$ в очереди распределения процессорного времени одного физического потока ЭВМ стоит несколько потоков экспериментальной программы, тем самым в результате позволяя экспериментальной программе "отвоевать" больше процессорного времени у других программ, чем при $t = 8$, где в очереди каждого потока ЭВМ стоит лишь один поток экспериментальной программы. Это и приводит к небольшому ускорению.

\section{Вывод}

	Алгоритм Флойда-Уоршелла для поиска кратчайших путей между всеми вершинами взвешенного ориентированного графа может быть выполнен в параллельном варианте.
	
	Асимптотическая вычислительная сложность последовательного и параллельного вариантов алгоритма соответственно равны $O(n^3)$ и $O(\dfrac{n^3}{t})$, где $n$ --- размер матрицы смежности графа, а $t$ --- кол-во потоков выполнения. Сложность по памяти для обоих вариантов составляет $O(n^2)$.
	
	Была написана программа, решающая задачу поиска кратчайших путей между всеми вершинами взвешенного ориентированного графа последовательным и параллельным вариантами алгоритма Флойда-Уоршелла. Результаты измерений времени работы программы для разного количества потоков выполнения подтвердили теоретические расчеты вычислительной сложности работы программы.
	
	Распараллеливание алгоритма Флойда-Уоршелла дает линейный обратно-пропорциональный количеству потоков прирост в скорости исполнения, поэтому определенно стоит при решении подобных задач на практике использовать параллельный вариант.

\end{document}
